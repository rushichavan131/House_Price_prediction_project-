{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I_fZVHYZy0ev",
        "outputId": "1c63877c-5366-45bb-c654-9bd440f66b4a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.2.tar.gz (317.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.3/317.3 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j in /usr/local/lib/python3.10/dist-packages (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.2-py2.py3-none-any.whl size=317812365 sha256=5e295c84befd4d04a225a75f6dae9b7f78e18f482f475f62f7d6fc4634c1a680\n",
            "  Stored in directory: /root/.cache/pip/wheels/34/34/bd/03944534c44b677cd5859f248090daa9fb27b3c8f8e5f49574\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.2\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark py4j\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName(\"Basics\").getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SG9yOye7gRef",
        "outputId": "b35f7600-89d8-4fcd-c1aa-159acefe1119"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JXBaNGWFzzfJ",
        "outputId": "26274a4a-6425-4074-843d-d011cbf18f02"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+--------+---+----+-------------+-----------+----------+\n",
            "|  status|   price|bed|bath|         city|      state|house_size|\n",
            "+--------+--------+---+----+-------------+-----------+----------+\n",
            "|for_sale|105000.0|  3|   2|     Adjuntas|Puerto Rico|     920.0|\n",
            "|for_sale| 80000.0|  4|   2|     Adjuntas|Puerto Rico|    1527.0|\n",
            "|for_sale| 67000.0|  2|   1|   Juana Diaz|Puerto Rico|     748.0|\n",
            "|for_sale|145000.0|  4|   2|        Ponce|Puerto Rico|    1800.0|\n",
            "|for_sale|179000.0|  4|   3|San Sebastian|Puerto Rico|    2520.0|\n",
            "|for_sale| 50000.0|  3|   1|       Ciales|Puerto Rico|    2040.0|\n",
            "|for_sale| 71600.0|  3|   2|        Ponce|Puerto Rico|    1050.0|\n",
            "|for_sale|100000.0|  2|   1|        Ponce|Puerto Rico|    1092.0|\n",
            "|for_sale|150000.0|  3|   2|   Juana Diaz|Puerto Rico|    1045.0|\n",
            "|for_sale| 79000.0|  5|   2|       Utuado|Puerto Rico|    1620.0|\n",
            "|for_sale|649000.0|  5|   5|        Ponce|Puerto Rico|    2677.0|\n",
            "|for_sale|120000.0|  3|   2|        Yauco|Puerto Rico|    1100.0|\n",
            "|for_sale|235000.0|  4|   4|     Mayaguez|Puerto Rico|    3450.0|\n",
            "|for_sale|105000.0|  3|   2|        Ponce|Puerto Rico|    1500.0|\n",
            "|for_sale| 50000.0|  2|   1|        Yauco|Puerto Rico|     621.0|\n",
            "|for_sale|122500.0|  3|   2|        Yauco|Puerto Rico|    1118.0|\n",
            "|for_sale|255000.0|  3|   2|San Sebastian|Puerto Rico|    1500.0|\n",
            "|for_sale|425000.0|  4|   3|        Ponce|Puerto Rico|    3000.0|\n",
            "|for_sale| 93000.0|  4|   2|   Guayanilla|Puerto Rico|    1300.0|\n",
            "|for_sale| 75000.0|  4|   2|       Manati|Puerto Rico|    1080.0|\n",
            "+--------+--------+---+----+-------------+-----------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "file_path = \"/content/drive/MyDrive/Project Dataset/modified_data1.csv\"\n",
        "\n",
        "housing = spark.read.csv(file_path, header=True, inferSchema=True)\n",
        "\n",
        "housing.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TjkB1v9j0f0a",
        "outputId": "3d6b7c57-0ccf-4bcc-dd08-ba4e4dcfa774"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "978906"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "housing.count()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import StringIndexer, OneHotEncoder\n",
        "\n",
        "# Identify categorical columns\n",
        "categorical_cols = ['city', 'state','status']  # Replace with your actual categorical column names\n",
        "\n",
        "# Create StringIndexer and OneHotEncoder objects\n",
        "indexers = [StringIndexer(inputCol=c, outputCol=\"{0}_indexed\".format(c)) for c in categorical_cols]\n",
        "encoders = [OneHotEncoder(inputCol=\"{0}_indexed\".format(c), outputCol=\"{0}_encoded\".format(c)) for c in categorical_cols]\n",
        "\n",
        "# Apply StringIndexer and OneHotEncoder to the DataFrame\n",
        "from pyspark.ml import Pipeline\n",
        "pipeline = Pipeline(stages=indexers + encoders)\n",
        "df_encoded = pipeline.fit(housing).transform(housing)\n",
        "\n",
        "# Show the encoded features\n",
        "df_encoded.select('city', 'city_indexed', 'city_encoded', 'state', 'state_indexed', 'state_encoded').show(5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Ap6NT0Ttq_m",
        "outputId": "b1253954-58b5-47e9-8428-b7704c755407"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+------------+--------------------+-----------+-------------+---------------+\n",
            "|         city|city_indexed|        city_encoded|      state|state_indexed|  state_encoded|\n",
            "+-------------+------------+--------------------+-----------+-------------+---------------+\n",
            "|     Adjuntas|     10316.0|(14116,[10316],[1...|Puerto Rico|         46.0|(53,[46],[1.0])|\n",
            "|     Adjuntas|     10316.0|(14116,[10316],[1...|Puerto Rico|         46.0|(53,[46],[1.0])|\n",
            "|   Juana Diaz|      6341.0|(14116,[6341],[1.0])|Puerto Rico|         46.0|(53,[46],[1.0])|\n",
            "|        Ponce|      3611.0|(14116,[3611],[1.0])|Puerto Rico|         46.0|(53,[46],[1.0])|\n",
            "|San Sebastian|      7243.0|(14116,[7243],[1.0])|Puerto Rico|         46.0|(53,[46],[1.0])|\n",
            "+-------------+------------+--------------------+-----------+-------------+---------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Train-test split"
      ],
      "metadata": {
        "id": "P-qOu5IPAHQw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.regression import LinearRegression\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "\n",
        "# Select the features and target variable\n",
        "assembler = VectorAssembler(inputCols=['bed', 'bath', 'house_size', 'city_encoded', 'state_encoded'], outputCol='feature')\n",
        "df_assembled = assembler.transform(df_encoded).select('feature', 'price')\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "train_data, test_data = df_assembled.randomSplit([0.8, 0.2], seed=42)"
      ],
      "metadata": {
        "id": "3h2LA3R68xMf"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qmwjfZ37Hd75"
      },
      "source": [
        "# Linear Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_ccBQRT4Ik3",
        "outputId": "b6b62670-16bb-488d-8339-c4bec2fd0968"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Root Mean Squared Error (RMSE): 109706.69606634983\n",
            "R-squared linear regression: 0.7552070632319697\n"
          ]
        }
      ],
      "source": [
        "# Create a LinearRegression model\n",
        "lr = LinearRegression(featuresCol='feature', labelCol='price')\n",
        "\n",
        "# Fit the model to the training data\n",
        "lr_model = lr.fit(train_data)\n",
        "\n",
        "# Make predictions on the testing data\n",
        "predictions = lr_model.transform(test_data)\n",
        "\n",
        "# Evaluate the model\n",
        "evaluator = RegressionEvaluator(labelCol='price', predictionCol='prediction', metricName='rmse')\n",
        "rmse = evaluator.evaluate(predictions)\n",
        "print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
        "\n",
        "# Evaluate the model using R-squared\n",
        "evaluator = RegressionEvaluator(labelCol='price', predictionCol='prediction', metricName='r2')\n",
        "r2 = evaluator.evaluate(predictions)\n",
        "print(\"R-squared linear regression:\", r2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pXPRakuGG8Tl"
      },
      "source": [
        "# Lasso Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "glNixmHAEcql",
        "outputId": "d4d95e63-b1d8-46d2-c203-65c53170694c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Root Mean Squared Error (RMSE) on test data: 109708.43407395305\n",
            "R-squared on test data: 0.7551993069988383\n"
          ]
        }
      ],
      "source": [
        "from pyspark.ml.regression import LinearRegression\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "\n",
        "# Create a LinearRegression model with Lasso regularization\n",
        "lasso = LinearRegression(featuresCol=\"feature\", labelCol=\"price\", elasticNetParam=1.0, regParam=0.1)  # elasticNetParam=1.0 for Lasso\n",
        "\n",
        "# Fit the model to the training data\n",
        "lasso_model = lasso.fit(train_data)\n",
        "\n",
        "# Make predictions on the test data\n",
        "predictions = lasso_model.transform(test_data)\n",
        "\n",
        "# Evaluate the model\n",
        "evaluator = RegressionEvaluator(labelCol=\"price\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
        "rmse = evaluator.evaluate(predictions)\n",
        "print(\"Root Mean Squared Error (RMSE) on test data:\", rmse)\n",
        "\n",
        "evaluator_r2 = RegressionEvaluator(labelCol=\"price\", predictionCol=\"prediction\", metricName=\"r2\")\n",
        "r2 = evaluator_r2.evaluate(predictions)\n",
        "print(\"R-squared on test data:\", r2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aCbB8mIAHDi8"
      },
      "source": [
        "# Ridge Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SxEwfGkeFQmP",
        "outputId": "ef2aeb17-0fdc-4ae4-bc15-6ab73a195697"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Root Mean Squared Error (RMSE) on test data: 109706.69715721073\n",
            "R-squared on test data: 0.7552070583638067\n"
          ]
        }
      ],
      "source": [
        "# Create a LinearRegression model with Ridge regularization\n",
        "ridge = LinearRegression(featuresCol=\"feature\", labelCol=\"price\", elasticNetParam=0.0, regParam=0.1)  # elasticNetParam=0.0 for Ridge\n",
        "\n",
        "# Fit the model to the training data\n",
        "ridge_model = ridge.fit(train_data)\n",
        "\n",
        "# Make predictions on the test data\n",
        "predictions = ridge_model.transform(test_data)\n",
        "\n",
        "# Evaluate the model\n",
        "evaluator = RegressionEvaluator(labelCol=\"price\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
        "rmse = evaluator.evaluate(predictions)\n",
        "print(\"Root Mean Squared Error (RMSE) on test data:\", rmse)\n",
        "\n",
        "evaluator_r2 = RegressionEvaluator(labelCol=\"price\", predictionCol=\"prediction\", metricName=\"r2\")\n",
        "r2 = evaluator_r2.evaluate(predictions)\n",
        "print(\"R-squared on test data:\", r2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#HyperParameter Tuning"
      ],
      "metadata": {
        "id": "nC42NF5awB0p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
        "\n",
        "# Create a LinearRegression model\n",
        "plr = LinearRegression(featuresCol=\"feature\", labelCol=\"price\")\n",
        "\n",
        "# Create a ParamGridBuilder to define the hyperparameter grid to search over\n",
        "param_grid = ParamGridBuilder() \\\n",
        "    .addGrid(plr.regParam, [0.01, 0.1, 1.0]) \\\n",
        "    .addGrid(plr.elasticNetParam, [0.0, 0.5, 1.0]) \\\n",
        "    .build()\n",
        "\n",
        "# Create a RegressionEvaluator for evaluating the model\n",
        "evaluator = RegressionEvaluator(labelCol=\"price\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
        "\n",
        "# Create a CrossValidator\n",
        "crossval = CrossValidator(estimator=plr,\n",
        "                          estimatorParamMaps=param_grid,\n",
        "                          evaluator=evaluator,\n",
        "                          numFolds=5)  # Use 5-fold cross-validation\n",
        "\n",
        "# Fit the model using CrossValidator (assuming 'train_data' is already defined)\n",
        "cv_model = crossval.fit(train_data)\n",
        "\n",
        "# Get the best model from cross-validation\n",
        "best_model = cv_model.bestModel\n",
        "\n",
        "# Make predictions on the test data (assuming 'test_data' is already defined)\n",
        "predictions = best_model.transform(test_data)\n",
        "\n",
        "# Evaluate the best model\n",
        "rmse = evaluator.evaluate(predictions)\n",
        "print(\"Root Mean Squared Error (RMSE) of best model:\", rmse)\n",
        "\n",
        "# Evaluate the model using R-squared\n",
        "evaluator_r2 = RegressionEvaluator(labelCol=\"price\", predictionCol=\"prediction\", metricName=\"r2\")\n",
        "r2 = evaluator_r2.evaluate(predictions)\n",
        "print(\"R-squared:\", r2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Evh-1okkwBCb",
        "outputId": "5963ef36-d1d0-4999-8a9b-15f55ebbea98"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Root Mean Squared Error (RMSE) of best model: 109703.78228553546\n",
            "R-squared: 0.7552200663305235\n",
            "R-squared: 0.7552200663305235\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SrSdPyikwZsw"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bE88blDuxfzi"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}